"""
Prediction Routes - Congestion prediction endpoints
FRD-06: AI-Based Congestion Prediction

Endpoints:
- GET /api/predictions - Get all current predictions
- GET /api/predictions/roads/{road_id} - Get road prediction
- GET /api/predictions/junction/{id} - Get junction prediction
- GET /api/predictions/alerts - Get prediction alerts
- GET /api/predictions/statistics - Get engine statistics
- GET /api/predictions/accuracy - Get accuracy metrics
- POST /api/predictions/configure - Configure prediction engine

Part of the Autonomous City Traffic Intelligence System.
"""

from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel
from typing import Optional, List, Dict, Any, Literal
import time

from app.prediction import (
    get_prediction_engine,
    get_congestion_classifier,
    get_prediction_validator,
    CongestionLevel
)


router = APIRouter(prefix="/api/predictions", tags=["predictions"])


# ============================================
# Response Models
# ============================================

class PredictionPoint(BaseModel):
    """Single prediction point"""
    timestamp: float
    minutesAhead: int
    predictedDensity: float
    congestionLevel: str


class CongestionPredictionResponse(BaseModel):
    """Congestion prediction for a location"""
    roadId: str
    predictedAt: float
    horizon: int
    confidence: float
    algorithm: str
    currentDensity: float
    maxCongestionLevel: str
    predictions: List[PredictionPoint]


class PredictionsResponse(BaseModel):
    """All predictions response"""
    totalRoads: int
    predictions: List[CongestionPredictionResponse]
    generatedAt: float
    nextUpdate: float


class PredictionAlertResponse(BaseModel):
    """Prediction alert"""
    alertId: str
    roadId: str
    predictedLevel: str
    predictedAtTime: float
    minutesAhead: int
    predictedDensity: float
    confidence: float
    severity: str
    message: str
    createdAt: float
    resolved: bool


class AlertsResponse(BaseModel):
    """Alerts response"""
    totalAlerts: int
    alerts: List[PredictionAlertResponse]


class ConfigureRequest(BaseModel):
    """Configure prediction engine request"""
    algorithm: Optional[str] = None
    horizon: Optional[int] = None


# ============================================
# Helper Functions
# ============================================

def _format_prediction(prediction, classifier) -> CongestionPredictionResponse:
    """Format a CongestionPrediction for API response"""
    classifications = classifier.classify_prediction(prediction)
    max_level = classifier.get_max_predicted_level(prediction)
    
    predictions_formatted = []
    for ts, density in prediction.predictions:
        level = classifications.get(ts, CongestionLevel.LOW)
        predictions_formatted.append(PredictionPoint(
            timestamp=ts,
            minutesAhead=int((ts - prediction.predicted_at) / 60),
            predictedDensity=round(density, 2),
            congestionLevel=level.value
        ))
    
    return CongestionPredictionResponse(
        roadId=prediction.road_id,
        predictedAt=prediction.predicted_at,
        horizon=prediction.prediction_horizon,
        confidence=round(prediction.confidence, 2),
        algorithm=prediction.algorithm,
        currentDensity=round(prediction.current_density, 2),
        maxCongestionLevel=max_level.value,
        predictions=predictions_formatted
    )


# ============================================
# Endpoints
# ============================================

@router.get("", response_model=PredictionsResponse)
async def get_all_predictions(
    roadIds: Optional[str] = Query(None, description="Comma-separated road IDs"),
    minConfidence: float = Query(0, ge=0, le=1, description="Minimum confidence threshold")
):
    """
    Get current congestion predictions for all or specified roads
    
    Returns predictions for next 10 minutes (configurable).
    Predictions are generated by time-series analysis or RL model.
    
    Response time target: < 200ms
    """
    engine = get_prediction_engine()
    classifier = get_congestion_classifier()
    
    if not engine or not classifier:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    # Parse road IDs
    road_id_list = None
    if roadIds:
        road_id_list = [r.strip() for r in roadIds.split(',')]
    
    # Get predictions
    predictions = engine.predict_all_roads(road_id_list)
    
    # Format response
    result = []
    for road_id, prediction in predictions.items():
        if prediction.confidence >= minConfidence:
            result.append(_format_prediction(prediction, classifier))
    
    current_time = time.time()
    
    return PredictionsResponse(
        totalRoads=len(result),
        predictions=result,
        generatedAt=current_time,
        nextUpdate=current_time + engine.update_frequency
    )


@router.get("/roads/{road_id}", response_model=CongestionPredictionResponse)
async def get_road_prediction(road_id: str):
    """
    Get congestion prediction for specific road
    
    Returns detailed prediction for the next 10 minutes.
    """
    engine = get_prediction_engine()
    classifier = get_congestion_classifier()
    
    if not engine or not classifier:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    prediction = engine.predict(road_id, force=True)
    
    if not prediction:
        raise HTTPException(
            status_code=404, 
            detail=f"No prediction available for road {road_id} (insufficient data)"
        )
    
    return _format_prediction(prediction, classifier)


@router.get("/junction/{junction_id}")
async def get_junction_prediction(
    junction_id: str,
    horizon: int = Query(10, ge=1, le=60, description="Prediction horizon in minutes")
):
    """
    Get aggregated prediction for a junction
    
    Aggregates predictions from all connected roads.
    """
    engine = get_prediction_engine()
    classifier = get_congestion_classifier()
    
    if not engine or not classifier:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    # Find roads connected to this junction (naming convention: R-{junctionA}-{junctionB})
    connected_roads = []
    for road_id in engine.density_history.keys():
        if junction_id in road_id:
            connected_roads.append(road_id)
    
    if not connected_roads:
        raise HTTPException(
            status_code=404,
            detail=f"No roads found connected to junction {junction_id}"
        )
    
    # Get predictions for connected roads
    predictions = engine.predict_all_roads(connected_roads)
    
    if not predictions:
        raise HTTPException(
            status_code=404,
            detail=f"No predictions available for junction {junction_id}"
        )
    
    # Aggregate predictions
    current_time = time.time()
    avg_current_density = 0
    avg_predicted_densities = [0.0] * horizon
    total_roads = len(predictions)
    
    for prediction in predictions.values():
        avg_current_density += prediction.current_density
        for i, (_, density) in enumerate(prediction.predictions[:horizon]):
            avg_predicted_densities[i] += density
    
    if total_roads > 0:
        avg_current_density /= total_roads
        avg_predicted_densities = [d / total_roads for d in avg_predicted_densities]
    
    # Get max predicted level
    max_level = CongestionLevel.LOW
    for density in avg_predicted_densities:
        level = classifier.classify_density(density)
        if list(CongestionLevel).index(level) > list(CongestionLevel).index(max_level):
            max_level = level
    
    return {
        'junctionId': junction_id,
        'connectedRoads': connected_roads,
        'predictedAt': current_time,
        'horizon': horizon,
        'currentDensity': round(avg_current_density, 2),
        'maxCongestionLevel': max_level.value,
        'predictions': [
            {
                'minutesAhead': i + 1,
                'avgPredictedDensity': round(d, 2),
                'congestionLevel': classifier.classify_density(d).value
            }
            for i, d in enumerate(avg_predicted_densities)
        ]
    }


@router.get("/alerts", response_model=AlertsResponse)
async def get_prediction_alerts(
    roadId: Optional[str] = Query(None, description="Filter by road ID"),
    severity: Optional[str] = Query(None, description="Filter by severity (INFO, WARNING, CRITICAL)"),
    active: bool = Query(True, description="Only active (unresolved) alerts"),
    limit: int = Query(50, ge=1, le=200)
):
    """
    Get prediction alerts
    
    Returns alerts generated when predictions indicate
    imminent congestion or unusual patterns.
    """
    classifier = get_congestion_classifier()
    
    if not classifier:
        raise HTTPException(status_code=500, detail="Classifier not initialized")
    
    # Get alerts
    if active:
        alerts = classifier.get_active_alerts(roadId)
    else:
        alerts = classifier.all_alerts
        if roadId:
            alerts = [a for a in alerts if a.road_id == roadId]
    
    # Filter by severity
    if severity:
        alerts = [a for a in alerts if a.severity.value == severity.upper()]
    
    # Limit
    alerts = alerts[:limit]
    
    # Format response
    formatted_alerts = [
        PredictionAlertResponse(
            alertId=a.alert_id,
            roadId=a.road_id,
            predictedLevel=a.predicted_level.value,
            predictedAtTime=a.predicted_at_time,
            minutesAhead=max(0, int((a.predicted_at_time - a.created_at) / 60)),
            predictedDensity=round(a.predicted_density, 2),
            confidence=round(a.confidence, 2),
            severity=a.severity.value,
            message=a.message,
            createdAt=a.created_at,
            resolved=a.resolved
        )
        for a in alerts
    ]
    
    return AlertsResponse(
        totalAlerts=len(formatted_alerts),
        alerts=formatted_alerts
    )


@router.post("/alerts/{alert_id}/resolve")
async def resolve_alert(alert_id: str):
    """Resolve (dismiss) an alert"""
    classifier = get_congestion_classifier()
    
    if not classifier:
        raise HTTPException(status_code=500, detail="Classifier not initialized")
    
    success = classifier.resolve_alert(alert_id)
    
    if not success:
        raise HTTPException(status_code=404, detail=f"Alert {alert_id} not found")
    
    return {'status': 'resolved', 'alertId': alert_id}


@router.get("/statistics")
async def get_prediction_statistics():
    """
    Get prediction engine statistics
    
    Returns information about prediction performance and configuration.
    """
    engine = get_prediction_engine()
    classifier = get_congestion_classifier()
    
    if not engine:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    engine_stats = engine.get_statistics()
    classifier_stats = classifier.get_statistics() if classifier else {}
    
    return {
        'engine': engine_stats,
        'classifier': classifier_stats,
        'timestamp': time.time()
    }


@router.get("/accuracy")
async def get_prediction_accuracy(
    timeWindow: int = Query(3600, ge=60, le=86400, description="Time window in seconds")
):
    """
    Get prediction accuracy metrics
    
    Returns accuracy metrics comparing predictions vs actual outcomes.
    """
    validator = get_prediction_validator()
    
    if not validator:
        return {
            'available': False,
            'message': 'Prediction validator not initialized',
            'timestamp': time.time()
        }
    
    accuracy = validator.get_accuracy_metrics(timeWindow)
    best_worst = validator.get_best_worst_predictions(limit=5)
    
    return {
        'accuracy': accuracy,
        'bestWorst': best_worst,
        'recentComparisons': validator.get_recent_comparisons(20),
        'timestamp': time.time()
    }


@router.get("/history/{road_id}")
async def get_prediction_history(
    road_id: str,
    duration: int = Query(3600, description="History duration in seconds")
):
    """
    Get prediction history for a road
    
    Returns historical predictions vs actual outcomes.
    """
    validator = get_prediction_validator()
    
    if not validator:
        return {
            'roadId': road_id,
            'available': False,
            'message': 'Prediction validator not initialized',
            'timestamp': time.time()
        }
    
    # Filter comparisons for this road
    cutoff = time.time() - duration
    comparisons = [
        c.to_dict() for c in validator.comparison_results
        if c.road_id == road_id and c.timestamp >= cutoff
    ]
    
    return {
        'roadId': road_id,
        'duration': duration,
        'comparisons': comparisons,
        'totalComparisons': len(comparisons),
        'timestamp': time.time()
    }


@router.post("/configure")
async def configure_prediction(config: ConfigureRequest):
    """
    Configure prediction engine
    
    Allows changing algorithm and prediction horizon at runtime.
    """
    engine = get_prediction_engine()
    
    if not engine:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    changes = []
    
    if config.algorithm:
        try:
            engine.set_algorithm(config.algorithm)
            changes.append(f"algorithm={config.algorithm}")
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
    
    if config.horizon is not None:
        engine.prediction_horizon = config.horizon
        changes.append(f"horizon={config.horizon}")
    
    # Clear cache to apply changes
    engine.clear_cache()
    
    return {
        'status': 'configured',
        'changes': changes,
        'currentConfig': {
            'algorithm': engine.algorithm,
            'horizon': engine.prediction_horizon,
            'updateFrequency': engine.update_frequency
        },
        'timestamp': time.time()
    }


@router.get("/model/status")
async def get_model_status():
    """
    Get prediction model status
    
    Returns information about the RL model and NN predictor.
    """
    engine = get_prediction_engine()
    
    if not engine:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    # Check NN predictor
    from app.prediction import get_nn_predictor, TORCH_AVAILABLE
    nn_predictor = get_nn_predictor()
    
    # Check RL predictor
    from app.prediction import get_rl_predictor
    rl_predictor = get_rl_predictor()
    
    return {
        'predictionMode': engine.algorithm,
        'algorithms': {
            'moving_average': True,
            'linear_trend': True,
            'exponential_smoothing': True,
            'neural_network': nn_predictor.is_available() if nn_predictor else False
        },
        'rlPredictor': {
            'available': rl_predictor.is_ready() if rl_predictor else False,
            'statistics': rl_predictor.get_statistics() if rl_predictor else None
        },
        'nnPredictor': {
            'available': nn_predictor.is_available() if nn_predictor else False,
            'pytorchAvailable': TORCH_AVAILABLE,
            'statistics': nn_predictor.get_statistics() if nn_predictor else None
        },
        'timestamp': time.time()
    }


@router.post("/clear-cache")
async def clear_prediction_cache():
    """Clear prediction cache"""
    engine = get_prediction_engine()
    
    if not engine:
        raise HTTPException(status_code=500, detail="Prediction engine not initialized")
    
    engine.clear_cache()
    
    return {
        'status': 'cache_cleared',
        'timestamp': time.time()
    }
